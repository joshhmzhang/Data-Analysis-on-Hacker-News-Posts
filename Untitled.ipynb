{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "In this project, we'll compare two different types of posts from Hacker News, a popular site where technology related stories (or 'posts') are voted and commented upon. The two types of posts we'll explore begin with either Ask HN or Show HN.\n",
    "\n",
    "Ask HN and Show HN posts are standard posts for Haker News in which users ask the Hacker News community a specific question or share some projects, product or in general some information.\n",
    "\n",
    "Users submit Ask HN posts to ask the Hacker News community a specific question, such as \"What is the best online course you've ever taken?\" Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "Part 1\n",
    "\n",
    "* Explores the most post on Hacker News？\n",
    "* Do Ask HN or Show HN receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "Part 2 (use pandas)\n",
    "\n",
    "* For all post, Determine if posts created at a certain time are more likely to receive more points. \n",
    "* Which users are popular in HN post?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "#Read the file in as a list of lists.\n",
    "from csv import reader\n",
    "open_file=open('HN_posts.csv')\n",
    "read_file=reader(open_file)\n",
    "hn=list(read_file)\n",
    "#Extract the first row of data, and assign it to the variable headers.\n",
    "hn_header=hn[0]\n",
    "#Remove the first row from hn.\n",
    "hn=hn[1:]\n",
    "#print first 5 rows of dataset:\n",
    "print(hn[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "1. Explores the most post on Hacker News？\n",
    "2. Do Ask HN or Show HN receive more comments on average?\n",
    "3. Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Ask HN' posted: 9139\n",
      "Number of 'Show HN' posted: 10158\n",
      "Number of 'Other' posted: 273822\n"
     ]
    }
   ],
   "source": [
    "# separate posts with Ask HN and Show HN types from other posts:\n",
    "#-----------------------------------------------------------------\n",
    "# create empty lists to store ask, show and other posts:\n",
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[]\n",
    "\n",
    "for row in hn:\n",
    "    #assign the title in each post to variable called title:\n",
    "    title = row[1]\n",
    "    #if title has 'Ask HN' phrase in it, add it to ask_posts list:\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    #if title has 'Show HN' phrase in it, add it to show_posts list:  \n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    #else add post to other_posts list:    \n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "\n",
    "print (\"Number of 'Ask HN' posted:\",len(ask_posts))\n",
    "print (\"Number of 'Show HN' posted:\",len(show_posts))\n",
    "print (\"Number of 'Other' posted:\",len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions about amount of Ask HN and Show HN posts on Hacker News:\n",
    "1. Number of Ask HN and Show HN posts is 9139 and 10158. \n",
    "2. About 3,1% of dataset is Ask HN posts (9139 out of 292724)\n",
    "3. About 3,5% of dataset is Show HN posts (10148 out of 293119)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "#comments on average for 'Ask HN'\n",
    "total_ask_comments=0\n",
    "\n",
    "for post in ask_posts:\n",
    "    total_ask_comments+=int(post[4])\n",
    "avg_ask_comments=total_ask_comments/len(ask_posts)\n",
    "\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "#comments on average for 'Show HN'\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.4572678601427205\n"
     ]
    }
   ],
   "source": [
    "#comments on average for 'Other'\n",
    "total_other_comments=0\n",
    "\n",
    "for post in other_posts:\n",
    "    total_other_comments+=int(post[4])\n",
    "avg_other_comments=total_other_comments/len(other_posts)\n",
    "print(avg_other_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions about amount of Ask HN and Show HN posts on Hacker News:\n",
    "On average, the comment received by ask posts in our sample is more Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best time to post\n",
    "We'll determine if ask posts created at a certain time are more likely to attract comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime\n",
    "dateformat='%m/%d/%Y %H:%M'\n",
    "for row in ask_posts:\n",
    "    date_clean=dt.datetime.strptime(row[-1],dateformat)\n",
    "    row[-1]=date_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n",
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n"
     ]
    }
   ],
   "source": [
    "#store time(only hour) and comment number in a list\n",
    "date_comment_only=[]\n",
    "for row in ask_posts:\n",
    "    #append can only add one list,so use .append[[list1],[list2]]\n",
    "    date_comment_only.append([row[-1].strftime('%H'),int(row[4])])\n",
    "\n",
    "count_by_hour={}\n",
    "comment_by_hour={}\n",
    "for row in date_comment_only:\n",
    "    time=row[0]\n",
    "    comment=row[1]\n",
    "    if time not in count_by_hour:\n",
    "        count_by_hour[time]=1\n",
    "        comment_by_hour[time]=comment\n",
    "    else:\n",
    "        count_by_hour[time]+=1\n",
    "        comment_by_hour[time]+=comment      \n",
    "        \n",
    "print(comment_by_hour)\n",
    "print(count_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('15', 28.68),\n",
       " ('13', 16.32),\n",
       " ('12', 12.38),\n",
       " ('02', 11.14),\n",
       " ('10', 10.68),\n",
       " ('04', 9.71),\n",
       " ('14', 9.69),\n",
       " ('17', 9.45),\n",
       " ('08', 9.19),\n",
       " ('11', 8.96),\n",
       " ('22', 8.8),\n",
       " ('05', 8.79),\n",
       " ('20', 8.75),\n",
       " ('21', 8.69),\n",
       " ('03', 7.95),\n",
       " ('18', 7.94),\n",
       " ('16', 7.71),\n",
       " ('00', 7.56),\n",
       " ('01', 7.41),\n",
       " ('19', 7.16),\n",
       " ('07', 7.01),\n",
       " ('06', 6.78),\n",
       " ('23', 6.7),\n",
       " ('09', 6.65)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average Comments Number for Ask HN Posts by Hour\n",
    "avg_comment_by_hour={}\n",
    "for hour in comment_by_hour:\n",
    "    avg_comment_by_hour[hour]=round(comment_by_hour[hour]/count_by_hour[hour],2)\n",
    "\n",
    "#Sort based on dict value\n",
    "sorted_avg_comment_by_hour = sorted(avg_comment_by_hour.items(), key=lambda kv: kv[1],reverse=True)\n",
    "sorted_avg_comment_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "15:00: 28.68 average comment per post\n",
      "13:00: 16.32 average comment per post\n",
      "12:00: 12.38 average comment per post\n",
      "02:00: 11.14 average comment per post\n",
      "10:00: 10.68 average comment per post\n"
     ]
    }
   ],
   "source": [
    "#Show top five 5 period with the most comment\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "for hr,comment in sorted_avg_comment_by_hour[:5]:\n",
    "    print('{}: {} average comment per post'.format(dt.datetime.strptime(hr,'%H').strftime('%H:%M'),comment))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Conclusion: \n",
    "The hour that receives the most comments per post on average is 15:00, with an average of 28.68 comments per post. There's about a 75% increase in the number of comments between the hours with the highest and second highest average number of comments.\n",
    "\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on the analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (use pandas)\n",
    "\n",
    "1. Determine if show or ask posts receive more points on average.\n",
    "2. Which users are popular in HN post?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "#read in the data set and convert the date\n",
    "df_hn = pd.read_csv('HN_posts.csv',parse_dates=['created_at'],index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Ten Posts \n",
    "\n",
    "Apple's letter to customer about the US Gov request to break into the iPhone received the most upvotes followed by a BBC article about the UK voting to leave the EU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11116274</th>\n",
       "      <td>A Message to Our Customers</td>\n",
       "      <td>http://www.apple.com/customer-letter/</td>\n",
       "      <td>5771</td>\n",
       "      <td>2016-02-17 08:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11966167</th>\n",
       "      <td>UK votes to leave EU</td>\n",
       "      <td>http://www.bbc.co.uk/news/uk-politics-36615028</td>\n",
       "      <td>3125</td>\n",
       "      <td>2016-06-24 03:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12494998</th>\n",
       "      <td>Pardon Snowden</td>\n",
       "      <td>https://www.pardonsnowden.org/</td>\n",
       "      <td>2553</td>\n",
       "      <td>2016-09-14 08:31:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12073675</th>\n",
       "      <td>Tell HN: New features and a moderator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2381</td>\n",
       "      <td>2016-07-11 19:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11390545</th>\n",
       "      <td>Ubuntu on Windows</td>\n",
       "      <td>http://blog.dustinkirkland.com/2016/03/ubuntu-...</td>\n",
       "      <td>2049</td>\n",
       "      <td>2016-03-30 16:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11893153</th>\n",
       "      <td>Microsoft to acquire LinkedIn for $26B</td>\n",
       "      <td>http://news.microsoft.com/2016/06/13/microsoft...</td>\n",
       "      <td>2049</td>\n",
       "      <td>2016-06-13 12:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11080701</th>\n",
       "      <td>Physicists Detect Gravitational Waves, Proving...</td>\n",
       "      <td>http://www.nytimes.com/2016/02/12/science/ligo...</td>\n",
       "      <td>2011</td>\n",
       "      <td>2016-02-11 15:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10226196</th>\n",
       "      <td>14-Year-Old Boy Arrested for Bringing Homemade...</td>\n",
       "      <td>http://techcrunch.com/2015/09/16/14-year-old-b...</td>\n",
       "      <td>1952</td>\n",
       "      <td>2015-09-16 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10982340</th>\n",
       "      <td>Request For Research: Basic Income</td>\n",
       "      <td>https://blog.ycombinator.com/basic-income</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016-01-27 19:23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136578</th>\n",
       "      <td>Why Im Suing the US Government</td>\n",
       "      <td>https://www.bunniestudios.com/blog/?p=4782</td>\n",
       "      <td>1855</td>\n",
       "      <td>2016-07-21 13:10:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "id                                                            \n",
       "11116274                         A Message to Our Customers   \n",
       "11966167                               UK votes to leave EU   \n",
       "12494998                                     Pardon Snowden   \n",
       "12073675              Tell HN: New features and a moderator   \n",
       "11390545                                  Ubuntu on Windows   \n",
       "11893153             Microsoft to acquire LinkedIn for $26B   \n",
       "11080701  Physicists Detect Gravitational Waves, Proving...   \n",
       "10226196  14-Year-Old Boy Arrested for Bringing Homemade...   \n",
       "10982340                 Request For Research: Basic Income   \n",
       "12136578                     Why Im Suing the US Government   \n",
       "\n",
       "                                                        url  num_points  \\\n",
       "id                                                                        \n",
       "11116274              http://www.apple.com/customer-letter/        5771   \n",
       "11966167     http://www.bbc.co.uk/news/uk-politics-36615028        3125   \n",
       "12494998                     https://www.pardonsnowden.org/        2553   \n",
       "12073675                                                NaN        2381   \n",
       "11390545  http://blog.dustinkirkland.com/2016/03/ubuntu-...        2049   \n",
       "11893153  http://news.microsoft.com/2016/06/13/microsoft...        2049   \n",
       "11080701  http://www.nytimes.com/2016/02/12/science/ligo...        2011   \n",
       "10226196  http://techcrunch.com/2015/09/16/14-year-old-b...        1952   \n",
       "10982340          https://blog.ycombinator.com/basic-income        1876   \n",
       "12136578         https://www.bunniestudios.com/blog/?p=4782        1855   \n",
       "\n",
       "                  created_at  \n",
       "id                            \n",
       "11116274 2016-02-17 08:38:00  \n",
       "11966167 2016-06-24 03:48:00  \n",
       "12494998 2016-09-14 08:31:00  \n",
       "12073675 2016-07-11 19:34:00  \n",
       "11390545 2016-03-30 16:35:00  \n",
       "11893153 2016-06-13 12:34:00  \n",
       "11080701 2016-02-11 15:37:00  \n",
       "10226196 2015-09-16 13:00:00  \n",
       "10982340 2016-01-27 19:23:00  \n",
       "12136578 2016-07-21 13:10:00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn[['title','url','num_points','created_at']].sort_values(by='num_points',ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best time to post (for all posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "12    16.785927\n",
       "2     16.406170\n",
       "11    16.192910\n",
       "13    16.109430\n",
       "0     15.879906\n",
       "1     15.555303\n",
       "4     15.403210\n",
       "5     15.375918\n",
       "19    15.362623\n",
       "18    15.279771\n",
       "10    15.034617\n",
       "3     15.010244\n",
       "17    14.987266\n",
       "8     14.941080\n",
       "15    14.757951\n",
       "6     14.750407\n",
       "7     14.740000\n",
       "21    14.580325\n",
       "16    14.509668\n",
       "23    14.504527\n",
       "9     14.499006\n",
       "22    14.127970\n",
       "14    14.051935\n",
       "20    13.607835\n",
       "Name: num_points, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn['hour'] = df_hn['created_at'].dt.hour\n",
    "df_groupby = df_hn.groupby(by='hour')\n",
    "df_groupby['num_points'].mean().sort_values(ascending=False)\n",
    "#should really strip out outliers before doing analyzing impact of hour of day or day of week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Midday is the best time to post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_of_week\n",
       "6    17.752834\n",
       "5    17.331082\n",
       "0    15.408457\n",
       "3    14.525682\n",
       "2    14.435828\n",
       "4    14.372634\n",
       "1    13.856638\n",
       "Name: num_points, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hn['day_of_week'] = df_hn['created_at'].dt.dayofweek\n",
    "df_groupby = df_hn.groupby(by='day_of_week')\n",
    "df_groupby['num_points'].mean().sort_values(ascending=False)\n",
    "#Monday is 0 and Sunday is 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the weekend is the best time to post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "ingve          69465\n",
       "prostoalex     32510\n",
       "jonbaer        26157\n",
       "nkurz          21085\n",
       "adamnemecek    21071\n",
       "walterbell     19810\n",
       "dnetesn        19253\n",
       "jseliger       17740\n",
       "uptown         16900\n",
       "DiabloD3       15846\n",
       "Name: num_points, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##top 10 users whose posts attract the most upvotes\n",
    "df_groupby = df_hn.groupby(by='author')\n",
    "df_groupby['num_points'].sum().sort_values(ascending=False)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "sama           425.200000\n",
       "epaga          284.954545\n",
       "dang           261.166667\n",
       "whoishiring    207.694444\n",
       "erlend_sh      192.812500\n",
       "firloop        192.588235\n",
       "urs2102        183.705882\n",
       "MarcScott      180.090909\n",
       "platz          173.636364\n",
       "potshot        166.800000\n",
       "Name: num_points, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 users who attracts the most upvotes per post on average (of those who have made more 10+ posts)\n",
    "df_groupby['num_points'].mean()[df_groupby['num_points'].count() > 9].sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Conclusion:\n",
    "\n",
    "The best time to post is at the midday during the weekend.\n",
    "ingve has attracted the most upvotes in total.\n",
    "Sam attracts the most upvotes per post on average (of those who have made more 10+ posts).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
